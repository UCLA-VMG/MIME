{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Large domain gap experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13597,
     "status": "ok",
     "timestamp": 1635843792688,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "O4S8QwoDBm0A",
    "outputId": "31a8165e-f9bc-4542-e3e7-dbd8a90cff78"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.image as img\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed\n",
    "sd = 0\n",
    "np.random.seed(sd)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(sd)\n",
    "random.seed(sd)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1635843792689,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "S2Dj2bSlHWau"
   },
   "outputs": [],
   "source": [
    "# dict to map given label to a number\n",
    "dict_gender_to_number = {'Male' : 0, \n",
    "                        'Female': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 111733,
     "status": "ok",
     "timestamp": 1635844036079,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "bCbAsG8WBm0F"
   },
   "outputs": [],
   "source": [
    "#Labels for humans (UTKFace)\n",
    "data_path = r'./dataset/humans/'\n",
    "\n",
    "data_labels = os.listdir(data_path)\n",
    "\n",
    "clean_labels = []\n",
    "\n",
    "age = []\n",
    "age2 = []\n",
    "gender = []\n",
    "race = []\n",
    "for f in data_labels:\n",
    "    temp = f.split('_')\n",
    "#     print(temp)\n",
    "    if len(temp[2])>1:\n",
    "        continue\n",
    "    age.append(temp[0])\n",
    "    age2.append(int(temp[0]))\n",
    "    gender.append(temp[1])\n",
    "    race.append(temp[2])\n",
    "    clean_labels.append(data_path+f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1635844038474,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "6zNcrZjBHWa0"
   },
   "outputs": [],
   "source": [
    "  \n",
    "gender_class = []\n",
    "for g in gender:\n",
    "    if g=='0':\n",
    "        gender_class.append('Male')\n",
    "    elif g=='1':\n",
    "        gender_class.append('Female')\n",
    "    else:\n",
    "        print('ErrorG')\n",
    "        print(g)\n",
    "        \n",
    "species_class = []\n",
    "for g in race:\n",
    "    species_class.append('Human')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1635844039559,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "3TNyjkeoHWbD",
    "outputId": "8c0c6f84-1f2d-4500-f2be-38b1b221f5d9"
   },
   "outputs": [],
   "source": [
    "#create pandas dataframe\n",
    "df = {'file': clean_labels, 'gender': gender_class, 'species': species_class}\n",
    "\n",
    "train_labels_humans = df = pd.DataFrame(data=df)\n",
    "train_labels_humans = train_labels_humans.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chicken data\n",
    "data_path = r'./dataset/chicken/male/'\n",
    "\n",
    "data_labels = os.listdir(data_path)\n",
    "\n",
    "clean_labels = []\n",
    "\n",
    "age = []\n",
    "age2 = []\n",
    "gender_class = []\n",
    "species_class = []\n",
    "race = []\n",
    "for f in data_labels:\n",
    "    gender_class.append('Male')\n",
    "    species_class.append('Chicken')\n",
    "    clean_labels.append(data_path+f)\n",
    "    \n",
    "\n",
    "    \n",
    "data_path = r'./dataset/chicken/female/'  \n",
    "data_labels = os.listdir(data_path)\n",
    "\n",
    "for f in data_labels:\n",
    "    gender_class.append('Female')\n",
    "    species_class.append('Chicken')\n",
    "    clean_labels.append(data_path+f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pandas dataframe\n",
    "df = {'file': clean_labels, 'gender': gender_class, 'species': species_class}\n",
    "\n",
    "train_labels_chicken = df = pd.DataFrame(data=df)\n",
    "train_labels_chicken = train_labels_chicken.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1635844049482,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "SAeMq19rBm0H"
   },
   "outputs": [],
   "source": [
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, data, path , transform = None):\n",
    "        super().__init__()\n",
    "        self.data = data.values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img_name = self.data[index][0]\n",
    "        label = dict_gender_to_number[self.data[index][1]] \n",
    "        label = torch.tensor(label)\n",
    "        img_path = os.path.join(img_name)\n",
    "        image1 = cv2.imread(img_path)\n",
    "        image = cv2.resize(image1, (100,100))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1635844049483,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "Bq-gQOk6Bm0I"
   },
   "outputs": [],
   "source": [
    "#transforms go here\n",
    "\n",
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "valid_transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1635844049783,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "J0L9DJeqHWbH"
   },
   "outputs": [],
   "source": [
    "#functions for data\n",
    "def resample_dataset_race(data,frac):\n",
    "    flagsD = data['species']=='Chicken'\n",
    "    flagsL = data['species']=='Human'\n",
    "    data_D = data[flagsD]\n",
    "    data_L = data[flagsL]\n",
    "    \n",
    "    data_D = equalize_dataset_gender(data_D,0.5)\n",
    "    data_L = equalize_dataset_gender(data_L,0.5)\n",
    "    \n",
    "    baseline = min(len(data_D),len(data_L))-2\n",
    "    \n",
    "    data_D = data_D.sort_values('gender')\n",
    "    data_L = data_L.sort_values('gender')\n",
    "\n",
    "    remD = len(data_D)-int((frac)*baseline)\n",
    "    tempD = data_D[int(0.5*remD):-int(0.5*remD)]\n",
    "    remL = len(data_L)-int((1-frac)*baseline)\n",
    "    tempL = data_L[int(0.5*remL):-int(0.5*remL)]\n",
    "    \n",
    "    print(baseline,remD,remL)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    frames = [tempD,tempL]\n",
    "    final_split = pd.concat(frames)\n",
    "    final_split = final_split.sample(frac=1)\n",
    "    \n",
    "    return final_split\n",
    "\n",
    "def resample_dataset_race_old(data,frac):\n",
    "    flagsD = data['species']=='Chicken'\n",
    "    flagsL = data['species']=='Human'\n",
    "    data_D = data[flagsD]\n",
    "    data_L = data[flagsL]\n",
    "\n",
    "    baseline = min(len(data_D),len(data_L))\n",
    "\n",
    "    \n",
    "    tempD = data_D[0:int(frac*baseline)]\n",
    "    tempL = data_L[0:int((1-frac)*baseline)]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    frames = [tempD,tempL]\n",
    "    final_split = pd.concat(frames)\n",
    "    final_split = final_split.sample(frac=1)\n",
    "    \n",
    "    return final_split\n",
    "\n",
    "def equalize_dataset_gender(data,frac):\n",
    "    flagsM = data['gender']=='Male'\n",
    "    flagsF = data['gender']=='Female'\n",
    "    data_M = data[flagsM]\n",
    "    data_F = data[flagsF]\n",
    "    baseline = min(len(data_M),len(data_F))\n",
    "    \n",
    "    tempM = data_M[0:int(baseline)]\n",
    "    tempF = data_F[0:int(baseline)]\n",
    "    frames = [tempM,tempF]\n",
    "    final_split = pd.concat(frames)\n",
    "    final_split = final_split.sample(frac=1)\n",
    "    \n",
    "    return final_split\n",
    "\n",
    "\n",
    "#functions for data\n",
    "def resample_dataset_equal(data):\n",
    "    flagsD = data['species']=='Chicken'\n",
    "    flagsL = data['species']=='Human'\n",
    "    data_D = data[flagsD]\n",
    "    data_L = data[flagsL]\n",
    "    \n",
    "    data_D = equalize_dataset_gender(data_D,0.5)\n",
    "    data_L = equalize_dataset_gender(data_L,0.5)\n",
    "    \n",
    "    baseline = min(len(data_D),len(data_L))\n",
    "    \n",
    "    data_D = data_D.sort_values('gender')\n",
    "    data_L = data_L.sort_values('gender')\n",
    "    \n",
    "#     tempD = data_D[0:int(frac*baseline)]\n",
    "#     tempL = data_L[0:int((1-frac)*baseline)]\n",
    "    remD = len(data_D)-int((0.5)*baseline)\n",
    "    tempD = data_D[int(0.5*remD):-int(0.5*remD)]\n",
    "    remL = len(data_L)-int((0.5)*baseline)\n",
    "    tempL = data_L[int(0.5*remL):-int(0.5*remL)]\n",
    "\n",
    "    \n",
    "    return tempD,tempL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test for chickens\n",
    "#generate base data\n",
    "train_split_t_h, test_labels_h = train_test_split(train_labels_humans, test_size=0.2)\n",
    "\n",
    "train_split_t_c, test_labels_c = train_test_split(train_labels_chicken, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "frames = [train_split_t_h,train_split_t_c]\n",
    "train_split_t = pd.concat(frames)\n",
    "\n",
    "frames = [test_labels_h,test_labels_c]\n",
    "test_labels = pd.concat(frames)\n",
    "print(test_labels['gender'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "test_split_D,test_split_L = resample_dataset_equal(test_labels)\n",
    "\n",
    "\n",
    "print(test_split_D['gender'].value_counts())\n",
    "print(test_split_D['species'].value_counts())\n",
    "\n",
    "print(test_split_L['gender'].value_counts())\n",
    "print(test_split_L['species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloaders: no validation set due to small dataset size\n",
    "batch_size = 30\n",
    "\n",
    "test_data_D = CombinedDataset(test_split_D, data_path, test_transform )\n",
    "test_data_L = CombinedDataset(test_split_L, data_path, test_transform )\n",
    "test_loader_D = DataLoader(dataset = test_data_D, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "test_loader_L = DataLoader(dataset = test_data_L, batch_size = batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1635844049785,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "QRjrTbWlHWbJ",
    "outputId": "c95add56-fa0e-43e0-e559-1a66bb9c1e89"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1635844049785,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "zmv_MA3mHWbK"
   },
   "outputs": [],
   "source": [
    "def test_performance(model,dataL,criterion):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    temp_test_acc = []\n",
    "\n",
    "    for data, target in dataL:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        # update-average-validation-loss \n",
    "        test_loss += loss.item() * data.size(0)\n",
    "\n",
    "        op_temp = output.detach().cpu().numpy()\n",
    "        op_temp = np.argmax(op_temp,axis=1)\n",
    "\n",
    "        test_acc += np.mean(op_temp==target.detach().cpu().numpy())*data.size(0)\n",
    "\n",
    "    ttacc  = test_acc/len(dataL.sampler)\n",
    "    test_loss_M = test_loss/len(dataL.sampler)\n",
    "    \n",
    "    test_print = 'Test Loss: {:.3f} \\tTest Acc: {:.3f}'.format(\n",
    "        test_loss_M, ttacc)\n",
    "\n",
    "    print(test_print)\n",
    "    return test_print, ttacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1635844049786,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "AiUmohixHWbK"
   },
   "outputs": [],
   "source": [
    "def write_file(fname,string,act):\n",
    "    with open(fname, act) as text_file:\n",
    "        text_file.write(string+'\\n')\n",
    "\n",
    "###Combined iteration\n",
    "def train_model(dark_frac,train_split_t,valid_loader,test_loader_D,test_loader_L):\n",
    "\n",
    "    num_epochs = 20\n",
    "    num_classes = 2  # for age\n",
    "    learning_rate = 0.0005\n",
    "\n",
    "    check_point_dir = 'chicken'+str(dark_frac)\n",
    "    \n",
    "    if not os.path.isdir(f\"checkpoints/\"+check_point_dir):\n",
    "        os.makedirs(f\"checkpoints/\"+check_point_dir)\n",
    "        print(\"Output directory is created\")\n",
    "        \n",
    "    #make logger text file\n",
    "    text_path = f\"checkpoints/\"+check_point_dir+\"/\"+\"log.txt\"\n",
    "    try:\n",
    "        os.remove(text_path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "    write_file(text_path,'********* Chicken fraction: {} *********'.format(dark_frac),'a')\n",
    "    \n",
    "    train_split = resample_dataset_race(train_split_t,dark_frac)\n",
    "    \n",
    "    write_file(text_path,str(train_split['species'].value_counts()),'a')\n",
    "    \n",
    "    write_file(text_path,str(train_split['gender'].value_counts()),'a')\n",
    "    \n",
    "    #Dataloaders\n",
    "    train_data = CombinedDataset(train_split, data_path, train_transform )\n",
    "\n",
    "    train_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    model = models.resnet34(pretrained=False)\n",
    "    model.fc = nn.Linear(512, num_classes)\n",
    "    model.load_state_dict(torch.load(f\"model_init_2class.pt\"))\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=learning_rate, \n",
    "        betas=(0.5, 0.999), \n",
    "        weight_decay=0.08\n",
    "        )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=30, \n",
    "        eta_min=0.01 * learning_rate, verbose=True\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Actual training of model\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    valid_accuracy = []\n",
    "    test_accuracy_D = []\n",
    "    test_accuracy_L = []\n",
    "\n",
    "\n",
    "    print(\"Training model...\")\n",
    "\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        # keep track of train/val loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        # training the model\n",
    "        model.train()\n",
    "        temp_train_acc = 0.0\n",
    "        for data, target in train_loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()                   # init gradients to zeros\n",
    "            output = model(data)           \n",
    "            loss = criterion(output, target)        # compute loss\n",
    "            loss.backward()                         # loss backwards\n",
    "            optimizer.step()                        # update model params\n",
    "\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            op_temp = output.detach().cpu().numpy()\n",
    "            op_temp = np.argmax(op_temp,axis=1)\n",
    "\n",
    "            temp_train_acc += np.mean(op_temp==target.detach().cpu().numpy())*data.size(0)\n",
    "            \n",
    "        \n",
    "        # validate-the-model\n",
    "        model.eval()\n",
    "        temp_val_acc = 0.0\n",
    "        for data, target in valid_loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # update-average-validation-loss \n",
    "            valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "            op_temp = output.detach().cpu().numpy()\n",
    "            op_temp = np.argmax(op_temp,axis=1)\n",
    "\n",
    "            temp_val_acc += np.mean(op_temp==target.detach().cpu().numpy())*data.size(0)\n",
    "\n",
    "        tvacc  = np.mean(np.array(temp_val_acc))\n",
    "\n",
    "        if tvacc>best_val_acc:\n",
    "            best_val_acc = tvacc\n",
    "            torch.save(model.state_dict(), f\"checkpoints/\"+check_point_dir+\"/model_best.pt\")\n",
    "            print('Model saved')\n",
    "            write_file(text_path,'Model saved','a')\n",
    "\n",
    "        # calculate-average-losses\n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        \n",
    "        ttacc  = temp_train_acc/len(train_loader.sampler)\n",
    "        tvacc  = temp_val_acc/len(valid_loader.sampler)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        train_accuracies.append(ttacc)\n",
    "        val_accuracies.append(tvacc)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # print-training/validation-statistics \n",
    "        train_print = 'Epoch: {} \\tTr Loss: {:.3f} \\tTr Acc: {:.3f} \\tVal Loss: {:.3f} \\tVal Acc: {:.3f}'.format(\n",
    "            epoch, train_loss, ttacc, valid_loss, tvacc)\n",
    "        print(train_print)\n",
    "\n",
    "        test_print_D, ttacc_D = test_performance(model,test_loader_D,criterion)\n",
    "        test_print_L, ttacc_L = test_performance(model,test_loader_L,criterion)\n",
    "        \n",
    "        valid_accuracy.append(tvacc)\n",
    "        test_accuracy_D.append(ttacc_D)\n",
    "        test_accuracy_L.append(ttacc_L)\n",
    "\n",
    "        write_file(text_path,train_print,'a')\n",
    "#         with open(text_path, \"w\") as text_file:\n",
    "#             text_file.write(train_print)\n",
    "        \n",
    "        write_file(text_path,test_print_D,'a')\n",
    "#         with open(text_path, \"w\") as text_file:\n",
    "#             text_file.write(test_print_D)\n",
    "        \n",
    "        write_file(text_path,test_print_L,'a')\n",
    "#         with open(text_path, \"w\") as text_file:\n",
    "#             text_file.write(test_print_L)\n",
    "            \n",
    "    path_val = f\"checkpoints/\"+check_point_dir+\"/\"+\"validation_accuracy\"\n",
    "    path_D = f\"checkpoints/\"+check_point_dir+\"/\"+\"test_accuracy_C\"\n",
    "    path_L = f\"checkpoints/\"+check_point_dir+\"/\"+\"test_accuracy_H\"\n",
    "    valid_accuracy = np.array(valid_accuracy)\n",
    "    test_accuracy_D = np.array(test_accuracy_D)\n",
    "    test_accuracy_L = np.array(test_accuracy_L)\n",
    "    np.save(path_val, valid_accuracy)\n",
    "    np.save(path_D, test_accuracy_D)\n",
    "    np.save(path_L, test_accuracy_L)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1635844049786,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "RXTp-Rq0n9ZQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13371524,
     "status": "ok",
     "timestamp": 1635857421301,
     "user": {
      "displayName": "Pradyumna Chari",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06555723454452599039"
     },
     "user_tz": 420
    },
    "id": "q6jdcZE4HWbR",
    "outputId": "35c4c338-080a-4955-8fb8-8f393d961e64"
   },
   "outputs": [],
   "source": [
    "dark_fracs = np.linspace(0.0,1.0,11)\n",
    "for dark_frac in dark_fracs:\n",
    "    print('********* Chicken fraction: {} *********'.format(dark_frac))\n",
    "    train_model(dark_frac,train_split_t,test_loader_D,test_loader_D,test_loader_L)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UTKFace_Model_Training-GenderClass-RaceClasses.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
