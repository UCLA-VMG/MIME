{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##UTKFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4S8QwoDBm0A"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.image as img\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.models as models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix random seed\n",
    "sd = 0\n",
    "np.random.seed(sd)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(sd)\n",
    "random.seed(sd)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict to map given label to a number\n",
    "dict_age_to_number = {'0-2': 0,\n",
    "                      '3-9' : 1,\n",
    "                      '10-19' : 2,\n",
    "                      '20-29' : 3,\n",
    "                      '30-39' : 4,\n",
    "                      '40-49' : 5,\n",
    "                      '50-59' : 6,\n",
    "                      '60-69' : 7,\n",
    "                      'more than 70' : 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "error",
     "timestamp": 1609973455543,
     "user": {
      "displayName": "MARCUS PEARCE",
      "photoUrl": "",
      "userId": "10460766432390124413"
     },
     "user_tz": 480
    },
    "id": "bCbAsG8WBm0F",
    "outputId": "9d3bafb7-22fe-4e3b-c63a-14e28ab5127e"
   },
   "outputs": [],
   "source": [
    "data_path = r'./UTKFace/'\n",
    "\n",
    "data_labels = os.listdir('UTKFace')\n",
    "\n",
    "clean_labels = []\n",
    "\n",
    "age = []\n",
    "age2 = []\n",
    "gender = []\n",
    "race = []\n",
    "for f in data_labels:\n",
    "    temp = f.split('_')\n",
    "    if len(temp[2])>1:\n",
    "        continue\n",
    "    age.append(temp[0])\n",
    "    age2.append(int(temp[0]))\n",
    "    gender.append(temp[1])\n",
    "    race.append(temp[2])\n",
    "    clean_labels.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign labels to samples\n",
    "age_class = []\n",
    "for a in age2:\n",
    "    if a<=2 and a>=0:\n",
    "        age_class.append('0-2')\n",
    "    elif a>=3 and a<=9:\n",
    "        age_class.append('3-9')\n",
    "    elif a>=10 and a<=19:\n",
    "        age_class.append('10-19')\n",
    "    elif a>=20 and a<=29:\n",
    "        age_class.append('20-29')\n",
    "    elif a>=30 and a<=39:\n",
    "        age_class.append('30-39')\n",
    "    elif a>=40 and a<=49:\n",
    "        age_class.append('40-49')\n",
    "    elif a>=50 and a<=59:\n",
    "        age_class.append('50-59')\n",
    "    elif a>=60 and a<=69:\n",
    "        age_class.append('60-69')\n",
    "    elif a>=70:\n",
    "        age_class.append('more than 70')\n",
    "    else:\n",
    "        print('ErrorA')\n",
    "        print(a)\n",
    "        \n",
    "gender_class = []\n",
    "for g in gender:\n",
    "    if g=='0':\n",
    "        gender_class.append('Male')\n",
    "    elif g=='1':\n",
    "        gender_class.append('Female')\n",
    "    else:\n",
    "        print('ErrorG')\n",
    "        print(g)\n",
    "        \n",
    "race_class = []\n",
    "for g in race:\n",
    "    if g=='0':\n",
    "        race_class.append('White')\n",
    "    elif g=='1':\n",
    "        race_class.append('Black')\n",
    "    elif g=='2':\n",
    "        race_class.append('Asian')\n",
    "    elif g=='3':\n",
    "        race_class.append('Indian')\n",
    "    elif g=='4':\n",
    "        race_class.append('Other')\n",
    "    else:\n",
    "        print('ErrorR')\n",
    "        print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pandas dataframe\n",
    "df = {'file': clean_labels, 'age': age_class, 'gender': gender_class, 'race': race_class}\n",
    "\n",
    "df = pd.DataFrame(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "executionInfo": {
     "elapsed": 21359,
     "status": "ok",
     "timestamp": 1609900039214,
     "user": {
      "displayName": "MARCUS PEARCE",
      "photoUrl": "",
      "userId": "10460766432390124413"
     },
     "user_tz": 480
    },
    "id": "8FVpLHAPBm0G",
    "outputId": "1773052e-fcd8-43d5-e98a-3c4978dfff61"
   },
   "outputs": [],
   "source": [
    "# categories\n",
    "age_list = ['3-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', 'more than 70']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#equalize proportions of ages\n",
    "for age in age_list:\n",
    "    print(age)\n",
    "    ff1 = (df.gender=='Male') & (df.age==age)\n",
    "    d1 = df[ff1]\n",
    "    \n",
    "    ff2 = (df.gender=='Female') & (df.age==age)\n",
    "    d2 = df[ff2]\n",
    "    ilist1 = df[((df.gender == 'Male') &( df.age == age) )].index\n",
    "    ilist2 = df[((df.gender == 'Female') &( df.age == age) )].index\n",
    "    \n",
    "    \n",
    "    \n",
    "    l1 = len(ilist1)\n",
    "    l2 = len(ilist2)\n",
    "    \n",
    "    remove = np.abs(l1-l2)\n",
    "\n",
    "    \n",
    "    if l1<l2:\n",
    "        df = df.drop(ilist2[0:remove])\n",
    "    elif l2<l1:\n",
    "        df = df.drop(ilist1[0:remove])\n",
    "\n",
    "train_labels = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAeMq19rBm0H"
   },
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "class UTKFaceDataset(Dataset):\n",
    "    def __init__(self, data, path , transform = None):\n",
    "        super().__init__()\n",
    "        self.data = data.values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img_name = self.data[index][0]\n",
    "        label = dict_age_to_number[self.data[index][1]]   # index 3 for race, need as tensor -> convert to number from str first\n",
    "        label = torch.tensor(label)\n",
    "        img_path = os.path.join(self.path, img_name)\n",
    "        image = img.imread(img_path)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bq-gQOk6Bm0I"
   },
   "outputs": [],
   "source": [
    "#Transforms go here\n",
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "valid_transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split datasets\n",
    "batch_size = 25\n",
    "\n",
    "def resample_dataset_gender(data,frac):\n",
    "    flagsM = data['gender']=='Male'\n",
    "    flagsF = data['gender']=='Female'\n",
    "    data_M = data[flagsM]\n",
    "    data_F = data[flagsF]\n",
    "    baseline = min(len(data_M),len(data_F))\n",
    "    \n",
    "    tempM = data_M[0:int(frac*baseline)]\n",
    "    tempF = data_F[0:int((1-frac)*baseline)]\n",
    "    frames = [tempM,tempF]\n",
    "    final_split = pd.concat(frames)\n",
    "    final_split = final_split.sample(frac=1)\n",
    "    \n",
    "    return final_split\n",
    "\n",
    "\n",
    "train_split_t, val_split_t_dash = train_test_split(train_labels, stratify=train_labels.gender, test_size=0.2)\n",
    "val_split_t, test_labels = train_test_split(val_split_t_dash, stratify=val_split_t_dash.gender, test_size=0.5)\n",
    "\n",
    "#Ensure val set has equal representation\n",
    "flagsM = val_split_t['gender']=='Male'\n",
    "flagsF = val_split_t['gender']=='Female'\n",
    "data_M = val_split_t[flagsM]\n",
    "data_F = val_split_t[flagsF]\n",
    "\n",
    "tempM = data_M\n",
    "tempF = data_F\n",
    "final_split = tempM\n",
    "val_split = final_split.sample(frac=1)\n",
    "\n",
    "flagsM = test_labels['gender']=='Male'\n",
    "flagsF = test_labels['gender']=='Female'\n",
    "test_split_M = test_labels[flagsM]\n",
    "test_split_F = test_labels[flagsF]\n",
    "\n",
    "print(test_split_M['gender'].value_counts())\n",
    "print(test_split_M['age'].value_counts())\n",
    "\n",
    "print(test_split_F['gender'].value_counts())\n",
    "print(test_split_F['age'].value_counts())\n",
    "\n",
    "\n",
    "valid_data = UTKFaceDataset(val_split, data_path, valid_transform )\n",
    "test_data_M = UTKFaceDataset(test_split_M, data_path, test_transform )\n",
    "test_data_F = UTKFaceDataset(test_split_F, data_path, test_transform )\n",
    "\n",
    "valid_loader = DataLoader(dataset = valid_data, batch_size = batch_size, shuffle=False, num_workers=0)\n",
    "test_loader_M = DataLoader(dataset = test_data_M, batch_size = batch_size, shuffle=False, num_workers=0)\n",
    "test_loader_F = DataLoader(dataset = test_data_F, batch_size = batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1609900084531,
     "user": {
      "displayName": "MARCUS PEARCE",
      "photoUrl": "",
      "userId": "10460766432390124413"
     },
     "user_tz": 480
    },
    "id": "w30YUMD1Bm0J",
    "outputId": "1e40cfbe-5726-47c4-f7fb-8174e118268f"
   },
   "outputs": [],
   "source": [
    "# CPU or GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(model,dataL,criterion):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    temp_test_acc = []\n",
    "\n",
    "    for data, target in dataL:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        # update-average-validation-loss \n",
    "        test_loss += loss.item() * data.size(0)\n",
    "\n",
    "        op_temp = output.detach().cpu().numpy()\n",
    "        op_temp = np.argmax(op_temp,axis=1)\n",
    "\n",
    "        test_acc += np.mean(op_temp==target.detach().cpu().numpy())*data.size(0)\n",
    "\n",
    "    ttacc  = test_acc/len(dataL.sampler)\n",
    "    test_loss_M = test_loss/len(dataL.sampler)\n",
    "    \n",
    "    test_print = 'Test Loss: {:.3f} \\tTest Acc: {:.3f}'.format(\n",
    "        test_loss_M, ttacc)\n",
    "\n",
    "    print(test_print)\n",
    "    return test_print,ttacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "def write_file(fname,string,act):\n",
    "    with open(fname, act) as text_file:\n",
    "        text_file.write(string+'\\n')\n",
    "\n",
    "###Combined iteration\n",
    "def train_model(male_frac,train_split_t,valid_loader,test_loader_M,test_loader_F):\n",
    "\n",
    "    num_epochs = 65\n",
    "    num_classes = 9  # for age\n",
    "    learning_rate = 0.0006\n",
    "\n",
    "    check_point_dir = 'male'+str(male_frac)\n",
    "    \n",
    "    if not os.path.isdir(f\"checkpoints/\"+check_point_dir):\n",
    "        os.makedirs(f\"checkpoints/\"+check_point_dir)\n",
    "        print(\"Output directory is created\")\n",
    "        \n",
    "    #make logger text file\n",
    "    text_path = f\"checkpoints/\"+check_point_dir+\"/\"+\"log.txt\"\n",
    "    try:\n",
    "        os.remove(text_path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "    write_file(text_path,'********* Male fraction: {} *********'.format(male_frac),'a')\n",
    "    \n",
    "    train_split = resample_dataset_gender(train_split_t,male_frac)\n",
    "    \n",
    "    write_file(text_path,str(train_split['age'].value_counts()),'a')\n",
    "    \n",
    "    write_file(text_path,str(train_split['gender'].value_counts()),'a')\n",
    "    \n",
    "    #Dataloaders\n",
    "    train_data = UTKFaceDataset(train_split, data_path, train_transform )\n",
    "\n",
    "    train_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    model = models.resnet34(pretrained=False)\n",
    "    model.fc = nn.Linear(512, num_classes)\n",
    "    model.load_state_dict(torch.load(f\"model_init_9class.pt\"))\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=learning_rate, \n",
    "        betas=(0.5, 0.999), \n",
    "        weight_decay=0.05\n",
    "        )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=num_epochs, \n",
    "        eta_min=0.01 * learning_rate, verbose=True\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Actual training of model\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    valid_accuracy = []\n",
    "    test_accuracy_M = []\n",
    "    test_accuracy_F = []\n",
    "\n",
    "    print(\"Training model...\")\n",
    "\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        # keep track of train/val loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        # training the model\n",
    "        model.train()\n",
    "        temp_train_acc = 0.0\n",
    "        for data, target in train_loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()                   # init gradients to zeros\n",
    "            output = model(data)                    # forward pass\n",
    "    #         print(output)\n",
    "    #         print(target)\n",
    "            loss = criterion(output, target)        # compute loss\n",
    "            loss.backward()                         # loss backwards\n",
    "            optimizer.step()                        # update model params\n",
    "\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            op_temp = output.detach().cpu().numpy()\n",
    "            op_temp = np.argmax(op_temp,axis=1)\n",
    "\n",
    "            temp_train_acc += np.mean(op_temp==target.detach().cpu().numpy())*data.size(0)\n",
    "            \n",
    "        \n",
    "        # validate-the-model\n",
    "        model.eval()\n",
    "        temp_val_acc = 0.0\n",
    "        for data, target in valid_loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # update-average-validation-loss \n",
    "            valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "            op_temp = output.detach().cpu().numpy()\n",
    "            op_temp = np.argmax(op_temp,axis=1)\n",
    "\n",
    "            temp_val_acc += np.mean(op_temp==target.detach().cpu().numpy())*data.size(0)\n",
    "\n",
    "        tvacc  = np.mean(np.array(temp_val_acc))\n",
    "\n",
    "        if tvacc>best_val_acc:\n",
    "            best_val_acc = tvacc\n",
    "            torch.save(model.state_dict(), f\"checkpoints/\"+check_point_dir+\"/model_best.pt\")\n",
    "            print('Model saved')\n",
    "            write_file(text_path,'Model saved','a')\n",
    "\n",
    "        # calculate-average-losses\n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        \n",
    "        ttacc  = temp_train_acc/len(train_loader.sampler)\n",
    "        tvacc  = temp_val_acc/len(valid_loader.sampler)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        train_accuracies.append(ttacc)\n",
    "        val_accuracies.append(tvacc)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # print-training/validation-statistics \n",
    "        train_print = 'Epoch: {} \\tTr Loss: {:.3f} \\tTr Acc: {:.3f} \\tVal Loss: {:.3f} \\tVal Acc: {:.3f}'.format(\n",
    "            epoch, train_loss, ttacc, valid_loss, tvacc)\n",
    "        print(train_print)\n",
    "\n",
    "        test_print_M,ttacc_M = test_performance(model,test_loader_M,criterion)\n",
    "        test_print_F,ttacc_F = test_performance(model,test_loader_F,criterion)\n",
    "\n",
    "        valid_accuracy.append(tvacc)\n",
    "        test_accuracy_M.append(ttacc_M)\n",
    "        test_accuracy_F.append(ttacc_F)\n",
    "        \n",
    "        write_file(text_path,train_print,'a')\n",
    "        \n",
    "        write_file(text_path,test_print_M,'a')\n",
    "        \n",
    "        write_file(text_path,test_print_F,'a')\n",
    "            \n",
    "    path_val = f\"checkpoints/\"+check_point_dir+\"/\"+\"validation_accuracy\"\n",
    "    path_M = f\"checkpoints/\"+check_point_dir+\"/\"+\"test_accuracy_M\"\n",
    "    path_F = f\"checkpoints/\"+check_point_dir+\"/\"+\"test_accuracy_F\"\n",
    "    valid_accuracy = np.array(valid_accuracy)\n",
    "    test_accuracy_F = np.array(test_accuracy_M)\n",
    "    test_accuracy_L = np.array(test_accuracy_F)\n",
    "    np.save(path_val, valid_accuracy)\n",
    "    np.save(path_M, test_accuracy_M)\n",
    "    np.save(path_F, test_accuracy_F)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_fracs = np.linspace(0.0,1.0,11)\n",
    "for male_frac in male_fracs:\n",
    "    print('********* Male fraction: {} *********'.format(male_frac))\n",
    "    train_model(male_frac,train_split_t,valid_loader,test_loader_M,test_loader_F)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MP_FairFace_Model_Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
