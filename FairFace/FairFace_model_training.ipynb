{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FairFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O4S8QwoDBm0A",
    "outputId": "308ac49d-6467-44a2-f11d-bdf5f04ce9f8"
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.image as img\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed for reproducability\n",
    "sd = 0\n",
    "np.random.seed(sd)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(sd)\n",
    "random.seed(sd)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2Dj2bSlHWau"
   },
   "outputs": [],
   "source": [
    "# Mapping a given label to a number\n",
    "dict_gender_to_number = {'Male' : 0, \n",
    "                        'Female': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCbAsG8WBm0F"
   },
   "outputs": [],
   "source": [
    "#Load data paths and labels\n",
    "\n",
    "train_labels = pd.read_csv(r'./fairface_label_train.csv')\n",
    "test_labels = pd.read_csv(r'./fairface_label_val.csv')\n",
    "data_path = r'./fairface-img-margin025-trainval/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAeMq19rBm0H"
   },
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "class FairFaceDataset(Dataset):\n",
    "    def __init__(self, data, path , transform = None):\n",
    "        super().__init__()\n",
    "        self.data = data.values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img_name = self.data[index][0]\n",
    "        label = dict_gender_to_number[self.data[index][2]]   \n",
    "        label = torch.tensor(label)\n",
    "        img_path = os.path.join(self.path, img_name)\n",
    "        image = img.imread(img_path)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bq-gQOk6Bm0I"
   },
   "outputs": [],
   "source": [
    "# Transforms go here\n",
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "valid_transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0L9DJeqHWbH"
   },
   "outputs": [],
   "source": [
    "#functions for data resampling\n",
    "def resample_dataset_race(data,frac):\n",
    "    flagsD = data['race']=='Black'\n",
    "    flagsL = data['race']=='White'\n",
    "    data_D = data[flagsD]\n",
    "    data_L = data[flagsL]\n",
    "    \n",
    "    data_D = equalize_dataset_gender(data_D,0.5)\n",
    "    data_L = equalize_dataset_gender(data_L,0.5)\n",
    "    \n",
    "    baseline = min(len(data_D),len(data_L))-2\n",
    "    \n",
    "    data_D = data_D.sort_values('gender')\n",
    "    data_L = data_L.sort_values('gender')\n",
    "    remD = len(data_D)-int((frac)*baseline)\n",
    "    tempD = data_D[int(0.5*remD):-int(0.5*remD)]\n",
    "    remL = len(data_L)-int((1-frac)*baseline)\n",
    "    tempL = data_L[int(0.5*remL):-int(0.5*remL)]\n",
    "    \n",
    "    print(baseline,remD,remL)\n",
    "    \n",
    "    frames = [tempD,tempL]\n",
    "    final_split = pd.concat(frames)\n",
    "    final_split = final_split.sample(frac=1)\n",
    "    \n",
    "    return final_split\n",
    "\n",
    "def resample_dataset_race_old(data,frac):\n",
    "    flagsD = data['race']=='Black'\n",
    "    flagsL = data['race']=='White'\n",
    "    data_D = data[flagsD]\n",
    "    data_L = data[flagsL]\n",
    "    \n",
    "    \n",
    "    baseline = min(len(data_D),len(data_L))\n",
    "    \n",
    "    tempD = data_D[0:int(frac*baseline)]\n",
    "    tempL = data_L[0:int((1-frac)*baseline)]\n",
    "    \n",
    "    frames = [tempD,tempL]\n",
    "    final_split = pd.concat(frames)\n",
    "    final_split = final_split.sample(frac=1)\n",
    "    \n",
    "    return final_split\n",
    "\n",
    "def equalize_dataset_gender(data,frac):\n",
    "    flagsM = data['gender']=='Male'\n",
    "    flagsF = data['gender']=='Female'\n",
    "    data_M = data[flagsM]\n",
    "    data_F = data[flagsF]\n",
    "    baseline = min(len(data_M),len(data_F))\n",
    "    \n",
    "    tempM = data_M[0:int(baseline)]\n",
    "    tempF = data_F[0:int(baseline)]\n",
    "    frames = [tempM,tempF]\n",
    "    final_split = pd.concat(frames)\n",
    "    final_split = final_split.sample(frac=1)\n",
    "    \n",
    "    return final_split\n",
    "\n",
    "\n",
    "#functions for data\n",
    "def resample_dataset_equal(data):\n",
    "    flagsD = data['race']=='Black'\n",
    "    flagsL = data['race']=='White'\n",
    "    data_D = data[flagsD]\n",
    "    data_L = data[flagsL]\n",
    "    \n",
    "    data_D = equalize_dataset_gender(data_D,0.5)\n",
    "    data_L = equalize_dataset_gender(data_L,0.5)\n",
    "    \n",
    "    baseline = min(len(data_D),len(data_L))\n",
    "    \n",
    "    data_D = data_D.sort_values('gender')\n",
    "    data_L = data_L.sort_values('gender')\n",
    "    \n",
    "    remD = len(data_D)-int((0.5)*baseline)\n",
    "    tempD = data_D[int(0.5*remD):-int(0.5*remD)]\n",
    "    remL = len(data_L)-int((0.5)*baseline)\n",
    "    tempL = data_L[int(0.5*remL):-int(0.5*remL)]\n",
    "\n",
    "    return tempD,tempL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gw6zXBp3HWbI",
    "outputId": "60657757-7335-4179-c937-b37db94c6417"
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 30\n",
    "\n",
    "train_split_t, val_split_t = train_test_split(train_labels, stratify=train_labels.gender, test_size=0.1)\n",
    "\n",
    "#Ensure val set has equal representation\n",
    "flagsD = val_split_t['race']=='Black'\n",
    "flagsL = val_split_t['race']=='White'\n",
    "data_L = val_split_t[flagsL]\n",
    "data_L = equalize_dataset_gender(data_L,0.5)\n",
    "\n",
    "data_D = val_split_t[flagsD]\n",
    "data_D = equalize_dataset_gender(data_D,0.5)\n",
    "\n",
    "val_split = data_L.sample(frac=1) \n",
    "\n",
    "test_split_D,test_split_L = resample_dataset_equal(test_labels)\n",
    "\n",
    "print(val_split['gender'].value_counts())\n",
    "print(val_split['race'].value_counts())\n",
    "\n",
    "print(test_split_D['gender'].value_counts())\n",
    "print(test_split_D['race'].value_counts())\n",
    "\n",
    "print(test_split_L['gender'].value_counts())\n",
    "print(test_split_L['race'].value_counts())\n",
    "\n",
    "#dataloaders\n",
    "valid_data = FairFaceDataset(val_split, data_path, valid_transform )\n",
    "test_data_D = FairFaceDataset(test_split_D, data_path, test_transform )\n",
    "test_data_L = FairFaceDataset(test_split_L, data_path, test_transform )\n",
    "valid_loader = DataLoader(dataset = valid_data, batch_size = batch_size, shuffle=False, num_workers=0)\n",
    "test_loader_D = DataLoader(dataset = test_data_D, batch_size = batch_size, shuffle=False, num_workers=0)\n",
    "test_loader_L = DataLoader(dataset = test_data_L, batch_size = batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRjrTbWlHWbJ",
    "outputId": "47a2c012-5a1a-4eaf-ebca-d6a0edaa962c"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmv_MA3mHWbK"
   },
   "outputs": [],
   "source": [
    "def test_performance(model,dataL,criterion):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    temp_test_acc = []\n",
    "\n",
    "    for data, target in dataL:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        # update-average-validation-loss \n",
    "        test_loss += loss.item() * data.size(0)\n",
    "\n",
    "        op_temp = output.detach().cpu().numpy()\n",
    "        op_temp = np.argmax(op_temp,axis=1)\n",
    "\n",
    "        test_acc += np.mean(op_temp==target.detach().cpu().numpy())*data.size(0)\n",
    "\n",
    "    ttacc  = test_acc/len(dataL.sampler)\n",
    "    test_loss_M = test_loss/len(dataL.sampler)\n",
    "    \n",
    "    test_print = 'Test Loss: {:.3f} \\tTest Acc: {:.3f}'.format(\n",
    "        test_loss_M, ttacc)\n",
    "\n",
    "    print(test_print)\n",
    "    return test_print, ttacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AiUmohixHWbK"
   },
   "outputs": [],
   "source": [
    "def write_file(fname,string,act):\n",
    "    with open(fname, act) as text_file:\n",
    "        text_file.write(string+'\\n')\n",
    "\n",
    "###Combined iteration\n",
    "def train_model(dark_frac,train_split_t,valid_loader,test_loader_D,test_loader_L):\n",
    "\n",
    "    num_epochs = 35\n",
    "    num_classes = 2 \n",
    "    learning_rate = 0.0005\n",
    "\n",
    "    check_point_dir = 'dark'+str(dark_frac)\n",
    "    \n",
    "    if not os.path.isdir(f\"checkpoints/\"+check_point_dir):\n",
    "        os.makedirs(f\"checkpoints/\"+check_point_dir)\n",
    "        print(\"Output directory is created\")\n",
    "        \n",
    "    #make logger text file\n",
    "    text_path = f\"checkpoints/\"+check_point_dir+\"/\"+\"log.txt\"\n",
    "    try:\n",
    "        os.remove(text_path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "    write_file(text_path,'********* Dark fraction: {} *********'.format(dark_frac),'a')\n",
    "    \n",
    "    train_split = resample_dataset_race(train_split_t,dark_frac)\n",
    "    \n",
    "    write_file(text_path,str(train_split['race'].value_counts()),'a')\n",
    "    \n",
    "    write_file(text_path,str(train_split['gender'].value_counts()),'a')\n",
    "    \n",
    "    #Dataloaders\n",
    "    train_data = FairFaceDataset(train_split, data_path, train_transform )\n",
    "\n",
    "    train_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    model = models.resnet34(pretrained=False)\n",
    "    model.fc = nn.Linear(512, num_classes)\n",
    "    model.load_state_dict(torch.load(f\"model_init_2class.pt\"))\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=learning_rate, \n",
    "        betas=(0.5, 0.999), \n",
    "        weight_decay=0.08\n",
    "        )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=30, \n",
    "        eta_min=0.01 * learning_rate, verbose=True\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Actual training of model\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    valid_accuracy = []\n",
    "    test_accuracy_D = []\n",
    "    test_accuracy_L = []\n",
    "\n",
    "\n",
    "    print(\"Training model...\")\n",
    "\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        # keep track of train/val loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        # training the model\n",
    "        model.train()\n",
    "        temp_train_acc = 0.0\n",
    "        for data, target in train_loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()                   # init gradients to zeros\n",
    "            output = model(data)                    # forward pass\n",
    "    #         print(output)\n",
    "    #         print(target)\n",
    "            loss = criterion(output, target)        # compute loss\n",
    "            loss.backward()                         # loss backwards\n",
    "            optimizer.step()                        # update model params\n",
    "\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            op_temp = output.detach().cpu().numpy()\n",
    "            op_temp = np.argmax(op_temp,axis=1)\n",
    "\n",
    "            temp_train_acc += np.mean(op_temp==target.detach().cpu().numpy())*data.size(0)\n",
    "            \n",
    "        \n",
    "        # validate-the-model\n",
    "        model.eval()\n",
    "        temp_val_acc = 0.0\n",
    "        for data, target in valid_loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # update-average-validation-loss \n",
    "            valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "            op_temp = output.detach().cpu().numpy()\n",
    "            op_temp = np.argmax(op_temp,axis=1)\n",
    "\n",
    "            temp_val_acc += np.mean(op_temp==target.detach().cpu().numpy())*data.size(0)\n",
    "\n",
    "        tvacc  = np.mean(np.array(temp_val_acc))\n",
    "\n",
    "        if tvacc>best_val_acc:\n",
    "            best_val_acc = tvacc\n",
    "            torch.save(model.state_dict(), f\"checkpoints/\"+check_point_dir+\"/model_best.pt\")\n",
    "            print('Model saved')\n",
    "            write_file(text_path,'Model saved','a')\n",
    "\n",
    "        # calculate-average-losses\n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        \n",
    "        ttacc  = temp_train_acc/len(train_loader.sampler)\n",
    "        tvacc  = temp_val_acc/len(valid_loader.sampler)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        train_accuracies.append(ttacc)\n",
    "        val_accuracies.append(tvacc)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # print-training/validation-statistics \n",
    "        train_print = 'Epoch: {} \\tTr Loss: {:.3f} \\tTr Acc: {:.3f} \\tVal Loss: {:.3f} \\tVal Acc: {:.3f}'.format(\n",
    "            epoch, train_loss, ttacc, valid_loss, tvacc)\n",
    "        print(train_print)\n",
    "\n",
    "        test_print_D, ttacc_D = test_performance(model,test_loader_D,criterion)\n",
    "        test_print_L, ttacc_L = test_performance(model,test_loader_L,criterion)\n",
    "        \n",
    "        valid_accuracy.append(tvacc)\n",
    "        test_accuracy_D.append(ttacc_D)\n",
    "        test_accuracy_L.append(ttacc_L)\n",
    "\n",
    "        write_file(text_path,train_print,'a')\n",
    "#         with open(text_path, \"w\") as text_file:\n",
    "#             text_file.write(train_print)\n",
    "        \n",
    "        write_file(text_path,test_print_D,'a')\n",
    "#         with open(text_path, \"w\") as text_file:\n",
    "#             text_file.write(test_print_D)\n",
    "        \n",
    "        write_file(text_path,test_print_L,'a')\n",
    "#         with open(text_path, \"w\") as text_file:\n",
    "#             text_file.write(test_print_L)\n",
    "            \n",
    "    path_val = f\"checkpoints/\"+check_point_dir+\"/\"+\"validation_accuracy\"\n",
    "    path_D = f\"checkpoints/\"+check_point_dir+\"/\"+\"test_accuracy_D\"\n",
    "    path_L = f\"checkpoints/\"+check_point_dir+\"/\"+\"test_accuracy_L\"\n",
    "    valid_accuracy = np.array(valid_accuracy)\n",
    "    test_accuracy_D = np.array(test_accuracy_D)\n",
    "    test_accuracy_L = np.array(test_accuracy_L)\n",
    "    np.save(path_val, valid_accuracy)\n",
    "    np.save(path_D, test_accuracy_D)\n",
    "    np.save(path_L, test_accuracy_L)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6jdcZE4HWbR",
    "outputId": "38c63744-b4f1-4c4f-c515-cfdbc869d06b"
   },
   "outputs": [],
   "source": [
    "dark_fracs = np.linspace(0.0,1.0,11)\n",
    "for dark_frac in dark_fracs:\n",
    "    print('********* Dark fraction: {} *********'.format(dark_frac))\n",
    "    train_model(dark_frac,train_split_t,valid_loader,test_loader_D,test_loader_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZveG0AfHWbY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UTKFace_Model_Training-GenderClass-RaceClasses.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
